# RotNet
DCNN for automatic rotation of pictures

# The task
Imagine we have a model deployed on the cloud which performs face recognition on images sent to it.This model works great on well-oriented images, i.e. images which are the right way up. However, when badly-oriented images are sent, e.g. upside-down images, the model performs poorly. Since we have no  control over how the images are sent and have no guarantee that the images will come with orientation-metadata, we would like a pre-processing step which fixes the orientation of the images before being sent to the main model.

# Data
The dataset of faces (merge of many dataset freely available on the web, http://www.face-rec.org/databases/) is available at my Kaggle profile page (https://www.kaggle.com/gasgallo/faces-data-new). It's a collection of around 8k pictures of different individuals in different poses. The amount of data should be enough to train the output layer of a pre-trained model.
Moreover, the compiled model, to use for inference, is available as well at my FloydHub account (https://www.floydhub.com/gasgallo/datasets/rotnet_resnet/).

# Build a model
It's easy to test some pre-trained models and adjust the output layer to do the rotation classfication job. So this is the approach used to solve the problem.
The data for the training was generated by randomly rotating original images and taking note of the related label (see "training.py").

# Create an API
